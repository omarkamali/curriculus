{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ultrachat bucketed curriculum (auto schedule)\n",
    "\n",
    "This notebook shows how to take conversation transcripts (e.g., **UltraChat**) and bucket them\n",
    "by turn count before feeding them into an automatically generated curriculum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "We'll make sure the local `curriculum` project is available on the Python path and import the\n",
    "helpers we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8688b508",
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip install datasets curriculus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "ROOT = Path.cwd()\n",
    "if not (ROOT / \"src\").exists():\n",
    "    ROOT = ROOT.parent\n",
    "if not (ROOT / \"src\").exists():\n",
    "    ROOT = ROOT.parent\n",
    "sys.path.insert(0, str(ROOT / \"src\"))\n",
    "\n",
    "from curriculus import Curriculus, CurriculusPlanner, generate_sequential_schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sample the UltraChat dataset (0.01%)\n",
    "We pull a thin 0.01% slice of the official `HuggingFaceH4/ultrachat_200k` dataset so the notebook\n",
    "runs quickly while still operating on real conversations.\n",
    "\n",
    "> ⚠️ The full dataset is ~1.6 GB. If you're running this outside the repo's CI, ensure you have\n",
    "> sufficient bandwidth and disk space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ULTRACHAT_DATASET = \"HuggingFaceH4/ultrachat_200k\"\n",
    "ULTRACHAT_SPLIT = \"train_sft[:1000]\"\n",
    "\n",
    "ultrachat_sample = load_dataset(ULTRACHAT_DATASET, split=ULTRACHAT_SPLIT)\n",
    "\n",
    "def to_conversation(row):\n",
    "    messages = row[\"messages\"]\n",
    "    return {\n",
    "        \"prompt_id\": row[\"prompt_id\"],\n",
    "        \"messages\": messages,\n",
    "        \"turn_count\": len(messages),\n",
    "    }\n",
    "\n",
    "ultrachat_subset = [to_conversation(row) for row in ultrachat_sample]\n",
    "len(ultrachat_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Bucketize by turn counts\n",
    "We map each conversation to a difficulty bucket using the requested ranges (0–4, 4–8, 8+ turns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'turns_6_12': 632, 'turns_12_18': 32, 'turns_0_6': 336}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def turn_bucket(turns: int) -> str:\n",
    "    if turns < 6:\n",
    "        return \"turns_0_6\"\n",
    "    if turns < 12:\n",
    "        return \"turns_6_12\"\n",
    "    if turns < 18:\n",
    "        return \"turns_12_18\"\n",
    "    return \"turns_18_plus\"\n",
    "\n",
    "bucketed = defaultdict(list)\n",
    "for convo in ultrachat_subset:\n",
    "    bucketed[turn_bucket(convo[\"turn_count\"])] .append(convo)\n",
    "\n",
    "{bucket: len(items) for bucket, items in bucketed.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build the curriculum dataset\n",
    "We order buckets from shortest to longest conversations and let `generate_sequential_schedule`\n",
    "    handle the fade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0,\n",
       "  {'turns_0_6': 1.0,\n",
       "   'turns_6_12': 0.0,\n",
       "   'turns_12_18': 0.0,\n",
       "   'turns_18_plus': 0.0}),\n",
       " (0.3333333333333333,\n",
       "  {'turns_0_6': 0.0,\n",
       "   'turns_6_12': 1.0,\n",
       "   'turns_12_18': 0.0,\n",
       "   'turns_18_plus': 0.0}),\n",
       " (0.6666666666666666,\n",
       "  {'turns_0_6': 0.0,\n",
       "   'turns_6_12': 0.0,\n",
       "   'turns_12_18': 1.0,\n",
       "   'turns_18_plus': 0.0}),\n",
       " (1.0,\n",
       "  {'turns_0_6': 0.0,\n",
       "   'turns_6_12': 0.0,\n",
       "   'turns_12_18': 0.0,\n",
       "   'turns_18_plus': 1.0})]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordered_names = [\"turns_0_6\", \"turns_6_12\", \"turns_12_18\", \"turns_18_plus\"]\n",
    "datasets = [{\"name\": name, \"dataset\": bucketed[name]} for name in ordered_names]\n",
    "schedule = generate_sequential_schedule(ordered_names)\n",
    "schedule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ WARNING: 'turns_12_18' shortage (32 vs 333). Scaling probability by 0.10x (best_effort=True).\n",
      "⚠️ WARNING: 'turns_18_plus' shortage (0 vs 166). Scaling probability by 0.00x (best_effort=True).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Total Steps: 1000\\\\nOversampling: False\\\\nBest Effort: True\\\\nDataset Budget:\\\\n  turns_0_6: OK           (336 available)\\\\n  turns_6_12: OK           (632 available)\\\\n  turns_12_18: SCALED       (32 available, 333 needed (0.10x))\\\\n  turns_18_plus: SCALED       (0 available, 166 needed (0.00x))'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "planner = CurriculusPlanner(\n",
    "    datasets=datasets,\n",
    "    schedule=schedule,\n",
    "    total_steps=sum(len(bucket) for bucket in bucketed.values()),\n",
    "    oversampling=False,\n",
    "    best_effort=True,\n",
    ")\n",
    "planner.get_plan_summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sample a preview\n",
    "We can now iterate the curriculum iterator and inspect how the mix changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ WARNING: 'turns_18_plus' shortage (0 vs 5). Scaling probability by 0.00x (best_effort=True).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'step': 0, 'bucket': 'turns_0_6', 'turns': 4},\n",
       " {'step': 1, 'bucket': 'turns_6_12', 'turns': 8},\n",
       " {'step': 2, 'bucket': 'turns_6_12', 'turns': 8},\n",
       " {'step': 3, 'bucket': 'turns_0_6', 'turns': 4},\n",
       " {'step': 4, 'bucket': 'turns_6_12', 'turns': 8},\n",
       " {'step': 5, 'bucket': 'turns_0_6', 'turns': 4},\n",
       " {'step': 6, 'bucket': 'turns_0_6', 'turns': 4},\n",
       " {'step': 7, 'bucket': 'turns_6_12', 'turns': 6},\n",
       " {'step': 8, 'bucket': 'turns_6_12', 'turns': 6},\n",
       " {'step': 9, 'bucket': 'turns_6_12', 'turns': 8},\n",
       " {'step': 10, 'bucket': 'turns_6_12', 'turns': 6},\n",
       " {'step': 11, 'bucket': 'turns_6_12', 'turns': 6},\n",
       " {'step': 12, 'bucket': 'turns_12_18', 'turns': 12},\n",
       " {'step': 13, 'bucket': 'turns_6_12', 'turns': 6},\n",
       " {'step': 14, 'bucket': 'turns_6_12', 'turns': 6},\n",
       " {'step': 15, 'bucket': 'turns_12_18', 'turns': 14},\n",
       " {'step': 16, 'bucket': 'turns_6_12', 'turns': 6},\n",
       " {'step': 17, 'bucket': 'turns_12_18', 'turns': 12},\n",
       " {'step': 18, 'bucket': 'turns_12_18', 'turns': 12},\n",
       " {'step': 19, 'bucket': 'turns_12_18', 'turns': 14},\n",
       " {'step': 20, 'bucket': 'turns_12_18', 'turns': 14},\n",
       " {'step': 21, 'bucket': 'turns_12_18', 'turns': 14},\n",
       " {'step': 22, 'bucket': 'turns_12_18', 'turns': 12},\n",
       " {'step': 23, 'bucket': 'turns_12_18', 'turns': 12},\n",
       " {'step': 24, 'bucket': 'turns_12_18', 'turns': 12},\n",
       " {'step': 25, 'bucket': 'turns_12_18', 'turns': 14},\n",
       " {'step': 26, 'bucket': 'turns_12_18', 'turns': 12},\n",
       " {'step': 27, 'bucket': 'turns_12_18', 'turns': 12},\n",
       " {'step': 28, 'bucket': 'turns_12_18', 'turns': 12},\n",
       " {'step': 29, 'bucket': 'turns_12_18', 'turns': 14}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curriculum_ds = Curriculus(\n",
    "    datasets=datasets,\n",
    "    schedule=schedule,\n",
    "    total_steps=30,\n",
    ")\n",
    "\n",
    "preview = []\n",
    "for step, sample in zip(range(30), curriculum_ds[\"train\"]):\n",
    "    preview.append({\"step\": step, \"bucket\": turn_bucket(sample[\"turn_count\"]), \"turns\": sample[\"turn_count\"]})\n",
    "\n",
    "preview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08821ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt_id', 'messages', 'turn_count'],\n",
       "    num_rows: 30\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curriculum_ds[\"train\"].to_hf_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9408269c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt_id': 'dd1afba7d2151b0695edea838378c8fd086d538e62a6643f67b24b7afeaf7f19',\n",
       " 'messages': [{'content': 'De León, previewing the speech he will give today, said he will highlight his Senate Bill 535, which directs a quarter of the proceeds from the Greenhouse Gas Reduction Fund to projects that benefit disadvantaged communities.\\nOn Thursday, de León nodded approvingly as a string of leading scientists and religious leaders gathered for hours of weedy policy discussions on the impacts of climate change, including gloomy predictions on mortality attributable to air pollution.\\nSEIU HEADS TO THE BAR: Employees of the State Bar of California represented by SEIU are planning a picket line today at the bar building in Los Angeles to protest the latest contract offer. What is the reason for SEIU employees planning a picket line at the State Bar of California building in Los Angeles?',\n",
       "   'role': 'user'},\n",
       "  {'content': 'The reason for SEIU employees planning a picket line at the State Bar of California building in Los Angeles is to protest the latest contract offer.',\n",
       "   'role': 'assistant'},\n",
       "  {'content': 'Can you provide more details about Senate Bill 535 and how it will benefit disadvantaged communities?',\n",
       "   'role': 'user'},\n",
       "  {'content': \"Sure, Senate Bill 535 is a California law that directs at least 25% of the money generated through the state's Greenhouse Gas Reduction Fund towards projects that benefit disadvantaged communities. The bill is designed to ensure that the benefits of California's climate policies, which include cap-and-trade, are felt most heavily by communities that have been disproportionately impacted by pollution and environmental degradation.\\n\\nThe funds generated through the bill are invested in projects that promote clean energy, reduce pollution, and support sustainable communities. This includes initiatives like public transportation, energy efficiency retrofits for low-income homes, and urban forestry projects.\\n\\nProponents of the bill argue that it helps to level the playing field for low-income communities and communities of color, which have historically faced greater exposure to environmental hazards and pollution. By directing funds towards these communities, the bill aims to create more equitable and sustainable outcomes for all Californians.\",\n",
       "   'role': 'assistant'}],\n",
       " 'turn_count': 4}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curriculum_ds[\"train\"].to_hf_dataset()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Where to go next\n",
    "- Experiment with custom schedules (e.g., hold short conversations longer).\n",
    "- Combine additional signals such as safety filters or topic tags."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
